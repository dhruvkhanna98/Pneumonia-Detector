{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "c3Lhd1S4oE7S",
    "outputId": "74510b13-11f3-471e-d988-e90fa45b7cad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B1fqb57ao4C2"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from collections import OrderedDict\n",
    "from torch import nn \n",
    "from torch import optim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vKM4J2kqldn9"
   },
   "outputs": [],
   "source": [
    "data_dir = 'drive/My Drive/PnemoniaGang/chest_xray'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/val'\n",
    "test_dir = data_dir + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X6C_-x06ldoA"
   },
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([transforms.Resize((224,224)), \n",
    "                                       transforms.ToTensor(), \n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "# Loading the Data \n",
    "train_data = datasets.ImageFolder(train_dir, transform = transforms)\n",
    "\n",
    "validation_data = datasets.ImageFolder(valid_dir, transform = transforms)\n",
    "\n",
    "test_data = datasets.ImageFolder(test_dir, transform = transforms)\n",
    "\n",
    "# DataLoaders \n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size = 32, shuffle = True, num_workers = 2)\n",
    "\n",
    "validloader = torch.utils.data.DataLoader(validation_data, batch_size = 32, num_workers = 2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size = 32, num_workers = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "NipCI_bTldoD",
    "outputId": "e492de5c-7d76-40a8-a24a-91ba19f12295"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    }
   ],
   "source": [
    "# Loading a Pre-trained Model\n",
    "model = models.densenet161(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yePQ4NINldoK"
   },
   "outputs": [],
   "source": [
    "# Freezing Parameters\n",
    "for param in model.parameters(): \n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.features.denseblock4:\n",
    "    param.requires_grad = True\n",
    "\n",
    "input_size = model.classifier.in_features\n",
    "output_size = 2\n",
    "hidden_size = 600\n",
    "\n",
    "classifier = nn.Sequential(nn.Linear(input_size, hidden_size),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Dropout(p=0.5),\n",
    "                           nn.BatchNorm1d(hidden_size),\n",
    "                           nn.Linear(hidden_size, output_size),\n",
    "                           nn.LogSoftmax(dim = 1))\n",
    "\n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dXbAqOvxldoM"
   },
   "outputs": [],
   "source": [
    "def validation(model, validloader, criterion): \n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    validation_loss = 0\n",
    "    \n",
    "    for inputs, labels in validloader: \n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        outputs = model(inputs).to(\"cuda\")\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += float(labels.size(0))\n",
    "        correct += float((predicted == labels).sum().item())\n",
    "        validation_loss += float(criterion(outputs, labels).item())\n",
    "    return validation_loss, correct, total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-F5O5l2Rd2Fi",
    "outputId": "0cc5b64b-59c6-49ce-e023-35dbfa24641d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7429, 0.2571], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights to compensate for the data Imbalance in the Testset classes\n",
    "\n",
    "input_weight = 1 - (1341/5216)\n",
    "label_weight = 1 - (3875/5216)\n",
    "\n",
    "weights = torch.cuda.FloatTensor([input_weight, label_weight])\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r20vfoX3ldoO"
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss(weight = weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 2, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "uFHDJpQLldoR",
    "outputId": "1e30eeba-c844-4b3b-e9ef-75c4d08bb3fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5..  Training Loss: 0.311..  Validation Loss: 0.271..  Validation Accuracy: 87.500\n",
      "Epoch: 1/5..  Training Loss: 0.186..  Validation Loss: 0.791..  Validation Accuracy: 68.750\n",
      "Epoch: 1/5..  Training Loss: 0.241..  Validation Loss: 0.485..  Validation Accuracy: 81.250\n",
      "Epoch: 1/5..  Training Loss: 0.217..  Validation Loss: 0.363..  Validation Accuracy: 81.250\n",
      "Epoch: 2/5..  Training Loss: 0.201..  Validation Loss: 1.080..  Validation Accuracy: 62.500\n",
      "Epoch: 2/5..  Training Loss: 0.154..  Validation Loss: 0.305..  Validation Accuracy: 93.750\n",
      "Epoch: 2/5..  Training Loss: 0.188..  Validation Loss: 0.475..  Validation Accuracy: 87.500\n",
      "Epoch: 2/5..  Training Loss: 0.286..  Validation Loss: 2.365..  Validation Accuracy: 56.250\n",
      "Epoch: 3/5..  Training Loss: 0.217..  Validation Loss: 1.351..  Validation Accuracy: 62.500\n",
      "Epoch: 3/5..  Training Loss: 0.162..  Validation Loss: 0.972..  Validation Accuracy: 75.000\n",
      "Epoch: 3/5..  Training Loss: 0.141..  Validation Loss: 0.591..  Validation Accuracy: 87.500\n",
      "Epoch: 3/5..  Training Loss: 0.162..  Validation Loss: 0.387..  Validation Accuracy: 87.500\n",
      "Epoch: 4/5..  Training Loss: 0.149..  Validation Loss: 0.252..  Validation Accuracy: 93.750\n",
      "Epoch: 4/5..  Training Loss: 0.155..  Validation Loss: 0.261..  Validation Accuracy: 93.750\n",
      "Epoch: 4/5..  Training Loss: 0.222..  Validation Loss: 0.200..  Validation Accuracy: 81.250\n",
      "Epoch: 4/5..  Training Loss: 0.207..  Validation Loss: 0.249..  Validation Accuracy: 87.500\n",
      "Epoch: 5/5..  Training Loss: 0.141..  Validation Loss: 0.294..  Validation Accuracy: 93.750\n",
      "Epoch: 5/5..  Training Loss: 0.207..  Validation Loss: 0.274..  Validation Accuracy: 93.750\n",
      "Epoch: 5/5..  Training Loss: 0.172..  Validation Loss: 0.202..  Validation Accuracy: 87.500\n",
      "Epoch: 5/5..  Training Loss: 0.217..  Validation Loss: 0.292..  Validation Accuracy: 93.750\n"
     ]
    }
   ],
   "source": [
    "steps = 0\n",
    "test_loss = 0\n",
    "accuracy = 0\n",
    "print_every = 40\n",
    "epochs = 5\n",
    "\n",
    "# Moving Model to GPU\n",
    "model.to('cuda')\n",
    "\n",
    "for e in range(epochs): \n",
    "    running_loss = 0\n",
    "    \n",
    "    # Decaying Learning Rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    for inputs, labels in trainloader: \n",
    "        steps += 1\n",
    "        \n",
    "        # Moving inputs and labels to GPU\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        \n",
    "        # Forward Pass on the Data\n",
    "        outputs = model.forward(inputs)\n",
    "        \n",
    "        # Loss after Forward Pass\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating Weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0: \n",
    "                # Model in Eval Mode for inference\n",
    "                model.eval()\n",
    "            \n",
    "                # Turning off gradients for validation\n",
    "                with torch.no_grad():\n",
    "                    validation_loss, correct, total = validation(model, validloader, criterion)\n",
    "                \n",
    "                    print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                          \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                          \"Validation Loss: {:.3f}.. \".format(validation_loss/len(validloader)),\n",
    "                          \"Validation Accuracy: {:.3f}\".format((correct/total)*100))\n",
    "                \n",
    "                    running_loss = 0\n",
    "                \n",
    "                # Putting Model back in Training mode\n",
    "                model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "cSu-aydildoU",
    "outputId": "4430257a-adcb-434a-8f52-d4ffaaeacdee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.341..  Test Accuracy: 90.224\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss, correct, total = validation(model, testloader, criterion)\n",
    "print(\"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)), \"Test Accuracy: {:.3f}\".format((correct/total)*100))  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Pneumonia Gang OG.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
